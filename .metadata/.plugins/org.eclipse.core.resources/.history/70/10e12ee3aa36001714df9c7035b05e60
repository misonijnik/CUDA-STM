#ifndef CUDASTM
#define CUDASTM
#include "helper/helper.cuh"
#include "structures/CUDAStructures.cuh"

#define MAX_VERSION 524288

typedef	struct
{
	unsigned version : 11;
	unsigned owner : 19;
	unsigned pre_locked : 1;
	unsigned locked : 1;
}gle;

typedef union
{
	gle entry;
	int i;
}GlobalLockEntry;



typedef	struct
{
	unsigned version : 11;
	unsigned index : 21;
}LocalLockEntry;

template<typename T>
struct ReadEntry
{
	T* cudaPtr;
	T value;
	unsigned version : 11;
};

template<typename T>
struct WriteEntry
{
	T* cudaPtr;
	T value;
};

template<typename T>
class GlobalLockTable
{
private:
	CUDAArray<GlobalLockEntry> _glt;
	T* _sharedMemPtr;
	size_t _memSize;
	size_t _wordSize;
	size_t _numberWordLock;
	size_t _length;
public:

	/*__host__ __device__ GlobalLockTable(const GlobalLockTable& table)
	{
		_sharedMemPtr = table._sharedMemPtr;
		_wordSize = table._wordSize;
		_memSize = table._memSize;
		_numberWordLock = table._numberWordLock;
		_length = table._length;
		_glt = table._glt;
	}*/

	__host__ GlobalLockTable(T* sharedMemPtr, size_t memSize, size_t numberWordLock)
	{
		_sharedMemPtr = sharedMemPtr;
		_wordSize = sizeof(T);
		_memSize = memSize*_wordSize;
		_numberWordLock = numberWordLock;
		_length = _memSize/(_wordSize*_numberWordLock);
		_glt = CUDAArray<GlobalLockEntry>(_length);
	}

	__device__ size_t getLength()
	{
		return _length;
	}

	__device__ GlobalLockEntry getEntryAt(unsigned int index)
	{
		return _glt.At(index);
	}

	__device__ GlobalLockEntry* getEntryAtPtr(unsigned int index)
	{
		return _glt.AtPtr(index);
	}

	__device__ GlobalLockEntry getEntryAt(T* cudaPtr)
	{
		return _glt.At(hash(cudaPtr));
	}

	__device__ GlobalLockEntry* getEntryAtPtr(T* cudaPtr)
	{
		return _glt.AtPtr(hash(cudaPtr));
	}

	__device__ void setEntryAt(T* cudaPtr, GlobalLockEntry entry)
	{
		_glt.SetAt(hash(cudaPtr), entry);
	}

	__host__ __device__ unsigned long hash(T* cudaPtr)
	{
		//TODO control range
		unsigned long tmp = (uintptr_t(cudaPtr) - (uintptr_t(_sharedMemPtr)))/(_wordSize*_numberWordLock);
		return tmp;
	}
};

template<typename T>
class LocalMetadata
{
private:
	GlobalLockTable<T>* g_lock;
	CUDALinkedList<ReadEntry<T> > readSet;
	CUDALinkedList<WriteEntry<T> > writeSet;
	CUDALinkedList<LocalLockEntry> lockSet;
	bool abort;

	__device__ GlobalLockEntry calcPreLockedVal(unsigned int version, unsigned int index)
	{
		GlobalLockEntry tmp;
		tmp.entry.version = version;
		tmp.entry.owner = index;
		tmp.entry.pre_locked = 1;
		tmp.entry.locked = 0;
		return tmp;
	}

	__device__ GlobalLockEntry calcLockedVal(unsigned int version)
	{
		GlobalLockEntry tmp;
		tmp.entry.version = version;
		tmp.entry.owner = 0;
		tmp.entry.pre_locked = 0;
		tmp.entry.locked = 1;
		return tmp;
	}

	__device__ GlobalLockEntry calcUnlockVal(unsigned int version)
	{
		GlobalLockEntry tmp;
		tmp.entry.version = version;
		tmp.entry.owner = 0;
		tmp.entry.pre_locked = 0;
		tmp.entry.locked = 0;
		return tmp;
	}

	__device__ bool tryPreLock()
	{
		Node<LocalLockEntry>* tmpNode = lockSet.getHead();
		GlobalLockEntry tmpLock;
		GlobalLockEntry preLockVal;
		while(tmpNode != NULL)
		{
			do
			{
				tmpLock = g_lock->getEntryAt(tmpNode->value.index);
				bool one = tmpLock.entry.version != tmpNode->value.version;
				bool two = tmpLock.entry.locked == 1;
				bool three = tmpLock.entry.pre_locked == 1;
				bool four = tmpLock.entry.owner < uniqueIndex();
				printf("thread %u: %u %u %u %u, %u\n", uniqueIndex(), one, two, three, four, tmpLock.entry.owner);
				if(tmpLock.entry.version != tmpNode->value.version || \
					tmpLock.entry.locked == 1 || \
					(tmpLock.entry.pre_locked == 1 && tmpLock.entry.owner < uniqueIndex()))
				{
					releaseLocks();
					return false;
				}
				preLockVal = calcPreLockedVal(tmpLock.entry.version, uniqueIndex());
			} while(atomicCAS((int*)g_lock->getEntryAtPtr(tmpNode->value.index), \
					tmpLock.i, preLockVal.i) != tmpLock.i);
			tmpNode = tmpNode->next;
		}
		return true;
	}


	__device__ bool tryLock()
	{
		Node<LocalLockEntry>* tmpNode = lockSet.getHead();
		GlobalLockEntry tmpLock;
		GlobalLockEntry preLockVal;
		GlobalLockEntry finalLockVal;
		while(tmpNode != NULL)
		{
			tmpLock = g_lock->getEntryAt(tmpNode->value.index);
			preLockVal = calcPreLockedVal(tmpLock.entry.version, uniqueIndex());
			finalLockVal = calcLockedVal(tmpLock.entry.version);
			if(atomicCAS((int*)(g_lock->getEntryAtPtr(tmpNode->value.index)), \
					preLockVal.i, finalLockVal.i) != preLockVal.i)
			{
				releaseLocks();
				return false;
			}
			tmpNode = tmpNode->next;
		}
		return true;
	}

public:
	LocalMetadata()
	{
		abort = false;
		g_lock = NULL;
	}

	__device__ LocalMetadata(GlobalLockTable<T>* glt)
	{
		abort = false;
		g_lock = glt;
	}

	__device__ void txStart()
	{
		readSet = CUDALinkedList<ReadEntry<T> >();
		writeSet = CUDALinkedList<WriteEntry<T> >();
		lockSet = CUDALinkedList<LocalLockEntry>();
		abort = false;
	}

	__device__ T txRead(T* ptr)
	{
		T val;
		if(g_lock->getEntryAt(ptr).entry.locked == 0)
		{
			bool isFound = false;
			Node<WriteEntry<T> >* tmpNode = writeSet.getHead();
			while(tmpNode != NULL)
			{
				if(tmpNode->value.cudaPtr == ptr)
				{
					isFound = true;
					val = tmpNode->value.value;
					break;
				}
				tmpNode = tmpNode->next;
			}
			if(!isFound)
			{
				ReadEntry<T> tmpReadEntry;
				tmpReadEntry.cudaPtr = ptr;
				tmpReadEntry.value = *ptr;
				tmpReadEntry.version = g_lock->getEntryAt(ptr).entry.version;
				readSet.push(tmpReadEntry);
				val = tmpReadEntry.value;
			}
		}
		else
		{
			val = 0;
			abort = true;
		}
		return val;
	}

	__device__ void txWrite(T* ptr, T val)
	{
		if(g_lock->getEntryAt(ptr).entry.locked == 0)
		{
			bool isFound = false;
			Node<WriteEntry<T> >* tmpNode = writeSet.getHead();
			while(tmpNode != NULL)
			{
				if(tmpNode->value.cudaPtr == ptr)
				{
					isFound = true;
					tmpNode->value.value = val;
					break;
				}
				tmpNode = tmpNode->next;
			}
			if(!isFound)
			{
				WriteEntry<T> tmpWriteEntry;
				tmpWriteEntry.value = val;
				tmpWriteEntry.cudaPtr = ptr;
				writeSet.push(tmpWriteEntry);
				LocalLockEntry tmpLocalLockEntry;
				tmpLocalLockEntry.index = g_lock->hash(ptr);
				tmpLocalLockEntry.version = g_lock->getEntryAt(ptr).entry.version;
				lockSet.push(tmpLocalLockEntry);
			}
		}
		else
		{
			abort = true;
		}
	}

	__device__ bool txValidate()
	{
		if(tryPreLock() == true)
		{
			Node<ReadEntry<T> >* tmpNode = readSet.getHead();
			while(tmpNode != NULL)
			{
				if(g_lock->getEntryAt(tmpNode->value.cudaPtr).entry.version != tmpNode->value.version)
				{
					return false;
				}
				tmpNode = tmpNode->next;
			}
			return tryLock();
		}
		else
		{
			return false;
		}
	}

	__device__ void txCommit()
	{
		Node<WriteEntry<T> >* tmpNode = writeSet.getHead();
		while(tmpNode != NULL)
		{
			*(tmpNode->value.cudaPtr) = tmpNode->value.value;
			printf("thread %u, value %d\n", uniqueIndex(),*(tmpNode->value.cudaPtr));
			tmpNode = tmpNode->next;
		}
		__threadfence();
		Node<LocalLockEntry>* tmpLockNode = lockSet.getHead();
		while(tmpLockNode != NULL)
		{
			if(tmpLockNode->value.version < MAX_VERSION)
			{
				(*(g_lock->getEntryAtPtr(tmpLockNode->value.index))).entry.version +=1;
			}
			else
			{
				(*(g_lock->getEntryAtPtr(tmpLockNode->value.index))).entry.version = 0;
			}
			printf("thread %u, version %u\n", uniqueIndex(),(*(g_lock->getEntryAtPtr(tmpLockNode->value.index))).entry.version);
			tmpLockNode = tmpLockNode->next;
		}
		//printf("thread %u\n", uniqueIndex());
	}


	__device__ void releaseLocks()
	{
		Node<LocalLockEntry>* tmpNode = lockSet.getHead();
		GlobalLockEntry preLockVal;
		GlobalLockEntry unLockVal;
		GlobalLockEntry tmpLock;
		while(tmpNode != NULL)
		{
			tmpLock = g_lock->getEntryAt(tmpNode->value.index);
			unLockVal = calcUnlockVal(tmpLock.entry.version);
			if(tmpLock.entry.pre_locked == 1)
			{
				preLockVal = calcPreLockedVal(tmpLock.entry.version, uniqueIndex());
				unsigned int tmp = atomicCAS((int*)g_lock->getEntryAtPtr(tmpNode->value.index), \
						preLockVal.i, unLockVal.i);
			}
			if(tmpLock.entry.locked == 1)
			{
				*(g_lock->getEntryAtPtr(tmpNode->value.index)) = unLockVal;
			}
			tmpNode = tmpNode->next;
		}
	}

	__device__ bool isAborted()
	{
		return abort;
	}

	__device__ CUDALinkedList<ReadEntry<T> >* getReadSet()
	{
		return &readSet;
	}

	__device__ CUDALinkedList<WriteEntry<T> >* getWriteSet()
	{
		return &writeSet;
	}

	__device__ CUDALinkedList<LocalLockEntry>* getLockSet()
	{
		return &lockSet;
	}
};




__host__ int hey();
__host__ int hey2();
__host__ int hey3();
__host__ int testGlt();
__global__ void testGltKernel(GlobalLockTable<int> g_lock, int* cudaPtr, int* val);
__global__ void changeArray(CUDAArray<WriteEntry<int> > arr, int* ptr, int val);
__global__ void testCorrectSTM(GlobalLockTable<int> g_lock, int* cudaPtr);

#endif
